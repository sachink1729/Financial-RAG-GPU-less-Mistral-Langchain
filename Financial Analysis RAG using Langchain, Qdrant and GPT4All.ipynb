{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62601663",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963f2620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install gpt4all\n",
    "# !pip install qdrant-client\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd892ac-f5ea-4e04-ae68-9fa316965582",
   "metadata": {},
   "source": [
    "## Set huggingface cache home (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b1d64b-12f4-417a-82de-3faf9e69ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cache_dir=\"huggingface/\"\n",
    "os.environ[\"HF_HOME\"] = cache_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8339c30b-240d-4a30-a699-61fed6e10f4e",
   "metadata": {},
   "source": [
    "## Check Device (assuming no GPU is available)\n",
    "\n",
    "I have a GPU available but for you it will print \"cpu\" if you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4564a8e1-57bb-4ffc-996c-b9d27999b53a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5824f34-3014-4425-b019-72298af53f43",
   "metadata": {},
   "source": [
    "## Enable to see Logs while running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81b9c154-9ae8-4084-b2b6-1fcb9f8a7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# # Configure logging\n",
    "# logging.basicConfig(level=logging.DEBUG,\n",
    "#                     format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Create a logger\n",
    "# logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404518cd-0bad-40be-94b9-f47190ffbe75",
   "metadata": {},
   "source": [
    "## Load Data, preprocessing and Creating Qdrant Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0799c19-bb4f-4d04-872a-9d21c72a5f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text_lower = text.lower()\n",
    "    text_no_punctuation = re.sub(r'[^\\w\\s\\$\\%\\.\\,\\\"\\'\\!\\?\\(\\)]', '', text_lower)\n",
    "    text_normalized_tabs = re.sub(r'(\\t)+', '', text_no_punctuation)\n",
    "    return text_normalized_tabs\n",
    "\n",
    "loader = PyPDFLoader(\"data/msft_annual_2023_report.pdf\")\n",
    "# loader = TextLoader(sample_texts)\n",
    "# loader = WebBaseLoader(\"https://cleartax.in/s/top-performing-nps-schemes\")\n",
    "documents = loader.load()\n",
    "for x in range(len(documents)):\n",
    "    # do preprocessing\n",
    "    documents[x].page_content=preprocess_text(documents[x].page_content)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0,separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\", \n",
    "                                   model_kwargs = {'device': \"cpu\"})  # forcefully setting device as cpu\n",
    "qdrant = Qdrant.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    location=\":memory:\",  # Local mode with in-memory storage only\n",
    "    collection_name=\"msft_data\",\n",
    "    force_recreate=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0718369-0b21-495e-97f7-b9487a3b9197",
   "metadata": {},
   "source": [
    "## Run if not able to download model using GPT4All directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1574c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download model\n",
    "\n",
    "# !mkdir models\n",
    "# !wget https://gpt4all.io/models/gguf/mistral-7b-instruct-v0.1.Q4_0.gguf -O models/mistral-7b-instruct-v0.1.Q4_0.gguf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cb1a0c-ab69-4204-9895-6c217a7738c7",
   "metadata": {},
   "source": [
    "## Directly calling GPT4All module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a199e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt4all import GPT4All\n",
    "model = GPT4All(model_name=\"mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "                             n_threads = 4,\n",
    "                             allow_download=True) # set allow_download as true to fetch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d422d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. The Bourne Identity (2004)\n",
      "2. The Bourne Supremacy (2006)\n",
      "3. The Bourne Ultimatum (2009)\n",
      "4. The Bourne Legacy (2012)\n",
      "5. Jason Bourne (2016)\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Jason Bourne movies list:\"\n",
    "print(model.generate(prompt, max_tokens=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aa975f-e5b3-4af2-840e-bc644dea42ae",
   "metadata": {},
   "source": [
    "## Creating prompts, tuning parameters and creating Chain using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575f9508-a594-4572-8210-90c7de877707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "template = '''[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\\n\n",
    "Context: {context}.\\n\n",
    "Question: {question}\\n\n",
    "Answer: '''\n",
    "rag_prompt = PromptTemplate(template=template, input_variables=[\"context\",\"question\"])\n",
    "\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "llm = GPT4All(\n",
    "            model=\"mistral-7b-instruct-v0.1.Q4_0.gguf\",\n",
    "            max_tokens=300,\n",
    "            n_threads = 4, \n",
    "            temp=0.3,\n",
    "            top_p=0.2,\n",
    "            top_k=40,\n",
    "            n_batch=8,\n",
    "            seed=100,\n",
    "            allow_download=True,\n",
    "            verbose=True)\n",
    "\n",
    "llm_chain = LLMChain(prompt=rag_prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56e21d-333f-4c16-97a8-abfc1f91f148",
   "metadata": {},
   "source": [
    "## Define format_docs for formatting context candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f09e379-caed-41c1-9c2d-b40c783623ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(query):\n",
    "    found_docs = qdrant.similarity_search_with_score(query,k=1)\n",
    "    return \"\\n\\n\".join(doc[0].page_content for doc in found_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e0014-39cd-4f45-9ec3-3887036dd03e",
   "metadata": {},
   "source": [
    "## Run Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af5f6ce-ae34-40a9-9824-e1778812768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: and selling our other products and service s and income taxes.  \n",
      "highlights from fiscal year 2023 compared with fiscal year 2022 included  \n",
      " microsoft cloud revenue increased 22% to $111.6  billion.  \n",
      " office commercial products and cloud services revenue increased 10% driven by office 365 commercial \n",
      "growth of 13%.  \n",
      " office consumer products and cloud services revenue increased 2% and microsoft 365 consumer subscribers \n",
      "increased to 67.0  million.  \n",
      " linkedin revenue increased 10%.  \n",
      " dynamics products and cloud services revenue increased 16% driven by dynamics 365 growth of 24%.  \n",
      " server products and cloud services revenue increased 19% driven by azure and other cloud services growth \n",
      "of 29%.  \n",
      " windows original equipment manufacturer licensing (windows oem) revenue decreased 25%.  \n",
      " devices revenue decreased 24%.  \n",
      " windows commercial products and cloud services revenue increased 5%.  \n",
      " xbox content and services revenue decreased 3%..\n",
      "\n",
      "Question: who were the top performers in 2023 for microsoft?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Microsoft Cloud Revenue - Increased by 22% to $111.6 billion, which is a significant growth compared to the previous year.\n",
      "2. Office Commercial Products and Cloud Services Revenue - Increased by 10%, driven by the growth of Office 365 commercial subscribers.\n",
      "3. LinkedIn Revenue - Increased by 10% in fiscal year 2023, which is a positive sign for Microsoft's overall performance.\n",
      "4. Dynamics Products and Cloud Services Revenue - Increased by 16%, driven by the growth of Dynamics 365 products.\n",
      "5. Server Products and Cloud Services Revenue - Increased by 19%, driven by the growth of Azure and other cloud services.\n",
      "CPU times: total: 3min 24s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"who were the top performers in 2023 for microsoft?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc03de8-75d2-4320-a2ca-f601d4b5473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: and selling our other products and service s and income taxes.  \n",
      "highlights from fiscal year 2023 compared with fiscal year 2022 included  \n",
      " microsoft cloud revenue increased 22% to $111.6  billion.  \n",
      " office commercial products and cloud services revenue increased 10% driven by office 365 commercial \n",
      "growth of 13%.  \n",
      " office consumer products and cloud services revenue increased 2% and microsoft 365 consumer subscribers \n",
      "increased to 67.0  million.  \n",
      " linkedin revenue increased 10%.  \n",
      " dynamics products and cloud services revenue increased 16% driven by dynamics 365 growth of 24%.  \n",
      " server products and cloud services revenue increased 19% driven by azure and other cloud services growth \n",
      "of 29%.  \n",
      " windows original equipment manufacturer licensing (windows oem) revenue decreased 25%.  \n",
      " devices revenue decreased 24%.  \n",
      " windows commercial products and cloud services revenue increased 5%.  \n",
      " xbox content and services revenue decreased 3%..\n",
      "\n",
      "Question: who were the worst performers in 2023 for microsoft?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "1. Windows OEM licensing revenue decreased by 25%, indicating that Microsoft's traditional business model of selling licenses to hardware manufacturers is not as profitable as it used to be.\n",
      "2. Devices revenue decreased by 24%, suggesting that the demand for physical devices such as laptops and tablets may be declining, or that there are other factors affecting this market segment.\n",
      "3. Xbox content and services revenue decreased by 3%, indicating that Microsoft's gaming business is not performing as well as expected.\n",
      "CPU times: total: 3min 52s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = \"who were the worst performers in 2023 for microsoft?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca0a8ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m[INST]: You are a financial expert analyst bot, below presents a context from which the a question will be asked, give your valuable insights as well.[\\INST]\n",
      "\n",
      "Context: year ended june  30, 2023  2022  2021  \n",
      "        \n",
      "united states (a) $ 106,744   $ 100,218   $ 83,953   \n",
      "other countries   105,171    98,052    84,135         \n",
      "total  $  211,915   $  198,270   $  168,088           \n",
      "(a) includes billings to oems and certain multinational organizations because of the nature of these businesses and the \n",
      "impracticability of determining the geographic source of the revenue.  \n",
      "revenue, classified by significant product and service offerings, was as follows  \n",
      "  \n",
      "(in millions)          \n",
      "        \n",
      "year ended june  30, 2023  2022  2021  \n",
      "        \n",
      "server products and cloud services  $ 79,970   $ 67,350   $ 52,589   \n",
      "office products and cloud services   48,728    44,862    39,872   \n",
      "windows   21,507    24,732    22,488   \n",
      "gaming   15,466    16,230    15,370   \n",
      "linkedin   15,145    13,816    10,289   \n",
      "search and news advertising   12,208    11,591    9,267   \n",
      "enterprise services   7,722    7,407    6,943   \n",
      "devices   5,521    7,306    7,143.\n",
      "\n",
      "Question: what was the revenue in united states versus in other countries in 2023?\n",
      "\n",
      "Answer: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The total revenue for the United States in 2023 was $106,744 million and the total revenue for other countries was $105,171 million. Therefore, the revenue generated by the United States was slightly higher than that of other countries in 2023.\n"
     ]
    }
   ],
   "source": [
    "query = \"what was the revenue in united states versus in other countries in 2023?\"\n",
    "resp = llm_chain.invoke(\n",
    "    input={\"question\":query,\n",
    "           \"context\": format_docs(query)\n",
    "          }\n",
    ")\n",
    "print(resp['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac365cc8-5e04-4f05-b900-ca44c907d6f3",
   "metadata": {},
   "source": [
    "## Other Queries ideas\n",
    "\n",
    "query = \"what was the expenses for research and development in 2023?\"\n",
    "\n",
    "query = \"what is microsoft 365 consumer count in 2023?\"\n",
    "\n",
    "query = \"what was the revenue generated by windows?\"\n",
    "\n",
    "query = \"what was the main focus for 2023?\"\n",
    "\n",
    "query = \"what's the overall stock information?\"\n",
    "\n",
    "query = \"what sector and companies did microsoft invest in 2023?\"\n",
    "\n",
    "query = \"how many people were laid off by microsoft and what were they offered?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bf6a38-1914-4b94-b804-292e03cc148f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
